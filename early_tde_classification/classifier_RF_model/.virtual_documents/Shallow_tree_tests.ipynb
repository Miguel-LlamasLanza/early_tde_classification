import os
import pandas as pd
from sklearn.preprocessing import StandardScaler



from early_tde_classification.config import Config

# Load data
feat_data = pd.read_csv(os.path.join(Config.OUT_FEATURES_DIR, 'features_all_tns_all_alerts.csv'), dtype = {"alertId": str})
feat_data.drop(columns = ["data_origin"], inplace = True)
feat_data.rename(columns={'objId': 'objectId'}, inplace=True)
print("Number of objects with extracted features: {}".format(len(feat_data)))
# Get TNS labels and merge them
tns_labels = pd.read_csv(os.path.join(Config.INPUT_DIR, 'ztf_tns_crossmatch.csv'))
# tns_labels.drop_duplicates(subset = ['objectId'], inplace = True)
tns_labels.dropna(subset='tns', inplace = True)

feat_data = feat_data.merge(tns_labels, on='objectId', how='left')
feat_data.rename(columns={'tns': 'tns_label'}, inplace=True)
print("Number of objects after crossmatching with TNS: {}".format(len(feat_data)))
# Drop nans
feat_data.dropna(subset='tns_label', inplace = True)
print("Number of objects after dropping NaN in TNS labels: {}".format(len(feat_data)))

# Separate features and labels
to_drop_for_features = {'objectId', 'alertId', 'type', 'tns_label', 'ref_time', 'err_ref_time',
   'err_amplitude', 'err_rise_time', 'err_temperature', 'std_flux_g', 'std_flux_g'}

features = feat_data.copy().drop(columns=to_drop_for_features)

scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
scaled_features = np.array(scaled_features)

# Modify the tns_label column to classify as 'TDE' or 'nonTDE'
feat_data['tde_or_not'] = feat_data['tns_label'].apply(
    lambda x: 'TDE' if 'TDE' in str(x) else 'nonTDE')
labels = feat_data['tde_or_not']



feat_data[feat_data['tde_or_not']=='TDE']
feat_data.columns


feat_data.tns_label.value_counts().plot(kind = 'bar')
np.unique(feat_data.tns_label)


import seaborn as sns
feat_data_tdes = feat_data[feat_data['tde_or_not']=='TDE']
feat_data_nontdes = feat_data[feat_data['tde_or_not']=='nonTDE']
# plt.scatter(feat_data_nontdes['rise_time'], feat_data_nontdes['temperature'], s = 2)
# plt.scatter(feat_data_tdes['rise_time'], feat_data_tdes['temperature'], s = 5)
# plt.xlim([0, 50])
sns.jointplot(feat_data, x = 'rise_time', y = 'temperature', hue = 'tde_or_not', s = 10, kind = 'kde')





# tns_labels.tns.value_counts(dropna = False).plot(kind = 'bar')
tns_labels[tns_labels.objectId == 'ZTF22abxacvm']





from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay



all_cm=[]
for seed in range(10):
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(scaled_features, labels, test_size=0.3, random_state=seed)
    
    # Create a shallow Decision Tree Classifier
    shallow_tree = RandomForestClassifier(random_state=seed, class_weight='balanced',
                                 n_jobs=10, n_estimators=300, max_depth=8)
    
    # Train the classifier
    shallow_tree.fit(X_train, y_train)
    
    # Predict on the test set
    y_pred = shallow_tree.predict(X_test)
    from sklearn.ensemble import RandomForestClassifier

    # # Evaluate the classifier
    # print("Accuracy:", accuracy_score(y_test, y_pred))
    # print("\nClassification Report:\n", classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred, labels=shallow_tree.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=shallow_tree.classes_)
    disp.plot()
    plt.show()
    
    all_cm.append(cm)



# Get confusion matrix
# cm = confusion_matrix(y_test, y_pred, labels=shallow_tree.classes_)
median_cm = np.median(all_cm, axis=0)

disp = ConfusionMatrixDisplay(confusion_matrix=median_cm, display_labels=shallow_tree.classes_)
disp.plot()
plt.show()
print(all_cm)



